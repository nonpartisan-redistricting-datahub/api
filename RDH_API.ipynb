{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the two libraries needed to run the script\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the baseurl used to retrieve the list of datasets on the website\n",
    "baseurl = 'https://redistrictingdatahub.org/wp-json/download/list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function retrieves a list of all datasets on the RDH site. In order to run, you must be an API user and registered with the RDH site.\n",
    "Inputs: username (string), password (string)\n",
    "Optional Inputs: form (string -- either 'csv' or 'json'), baseurl\"\"\"\n",
    "def get_list(username, password, form='csv', baseurl=baseurl):\n",
    "    print('Retrieving list of datasets on RDH Website...')\n",
    "    params = {}\n",
    "    params['username'] = username\n",
    "    params['password'] = password\n",
    "    params['format'] = form\n",
    "    r = requests.get(baseurl, params=params)\n",
    "    #Write the request to a file in the current workig directory\n",
    "    open('RDH_FileListing.'+form, 'wb').write(r.content)\n",
    "    print('List of datasets retrieved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function reads in the list of datasets as a pandas dataframe.\n",
    "Optional input: form (string -- either 'csv' or 'json')\"\"\"\n",
    "def read_list(form='csv'):\n",
    "    if form == 'csv':\n",
    "        df = pd.read_csv(r'./RDH_FileListing.csv')\n",
    "    else:\n",
    "        df = pd.read_json(r'./RDH_FileListing.json')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function checks all strings in a list and returns either True or False based on if the the string is in that row\n",
    "Inputs: string list (list), and row\n",
    "Outputs: T/F\"\"\"\n",
    "def check_string(string_list, row):\n",
    "    check_list = []\n",
    "    for i in string_list:\n",
    "        if i in row:\n",
    "            #If the string from the list is in the row being searched, add True to the check_list\n",
    "            check_list.append(True)\n",
    "        else:\n",
    "            #if it isn't, add False\n",
    "            check_list.append(False)\n",
    "    #make the list a set to eliminate duplicate values\n",
    "    check_list = set(check_list)\n",
    "    if len(check_list) == 1:\n",
    "        if any('True') in check_list:\n",
    "            #if the lenght of the set is 1 (one value between T/F) AND that value is True, return True\n",
    "            return True\n",
    "        else:\n",
    "            #If there is any False value, return False\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''This function extracts the data that meets input specifications to the current working directory. In order to run, you must be an API user and registered with the RDH site.\n",
    "Inputs: username (string), password (string), state_name (string), add_string (list of strings)\n",
    "Output: N/A'''\n",
    "def get_data(username,password,state_name,add_string):\n",
    "    #get list of datasets\n",
    "    get_list(username,password)\n",
    "    #read in the list\n",
    "    df = read_list()\n",
    "    params = (\n",
    "    ('username', username),\n",
    "    ('password', password),\n",
    "    )\n",
    "    #subset the df by state name\n",
    "    df['Subset'] = df['State'].apply(lambda x: True if x==state_name else False)\n",
    "    df = df[df['Subset']==True]\n",
    "    #subset the df by the additional string info\n",
    "    df['Subset'] = df['Title'].apply(lambda x: check_string(add_string,x))\n",
    "    #df['Subset'] = df['Title'].apply(lambda x: True if add_string in str(x) else False)\n",
    "    df = df[df['Subset']==True]\n",
    "    #take all of the urls in the subset df and split them to just get the baseurl of the dataset (no params)\n",
    "    urls = list(df['Download URL'])\n",
    "    new_urls = []\n",
    "    for i in urls:\n",
    "        new = i.split('?')[0]\n",
    "        new_urls.append(new)\n",
    "    counter = 1\n",
    "    #iterate over all of the new urls and retrieve the data\n",
    "    for i in new_urls:\n",
    "        print('Retrieving', str(counter), 'of',str(len(new_urls)),'files')\n",
    "        #get the data from the url and the params listed above\n",
    "        response = requests.get(i,params)\n",
    "        #get the file name of the dataset\n",
    "        file_name = i.split('%2F')[-1]\n",
    "        file_name = file_name.split('/')[-1]\n",
    "        file_name_no_zip = file_name.split('.')[0]\n",
    "        zipdot = '.'+file_name.split('.')[1]\n",
    "        #because we have multiple datasets with the same name (for CSV and SHP), but we may want SHP or CSV, we need to make them unique filenames\n",
    "        if 'csv' in i:\n",
    "            dtype = '_csv'\n",
    "        else:\n",
    "            dtype = '_shp'\n",
    "        #new filename\n",
    "        file_name = file_name_no_zip+dtype+zipdot\n",
    "        print('Retrieving ', file_name)\n",
    "        #write the data\n",
    "        file = open(file_name, \"wb\")\n",
    "        file.write(response.content)\n",
    "        file.close()\n",
    "        #print(response.url)\n",
    "        counter = counter+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDH Username: spencer.rdh.test\n",
      "RDH Password: UCb#(\\TE4afx`#HQ\n",
      "What state do you want data for? missouri\n",
      "Any other parameters? Please separate by comma (e.g. VEST, 2011, precinct, shp, csv). VEST, 2016\n"
     ]
    }
   ],
   "source": [
    "#Instantiate the inputs to be run\n",
    "username = str(input('RDH Username: '))\n",
    "password = str(input('RDH Password: '))\n",
    "\n",
    "state = str(input('What state do you want data for? '))\n",
    "state = state.capitalize()\n",
    "string = str(input('Any other parameters? Please separate by comma (e.g. VEST, 2011, precinct, shp, csv). '))\n",
    "string = [i.strip() for i in string.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving list of datasets on RDH Website...\n",
      "List of datasets retrieved.\n",
      "Retrieving 1 of 1 files\n",
      "Retrieving  mo_vest_16_shp.zip\n"
     ]
    }
   ],
   "source": [
    "get_data(username,password,state,string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
