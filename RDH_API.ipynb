{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script can be used to extract data from the RDH API. Designated API users can \"Run All\" and fill out the prompts as needed (e.g. username/email, password, states of interest, filtering paramters, etc.). You should not have to modify any of the code to retrieve data from the API, which will be extracted to the directory in which this script is housed on your system. Please note that there is additional information about datasets on our website: redistrictingdatahub.org. Should you be interested in this information, please navigate to your state(s) of interest and then desired dataset(s). If you have any questions or requests about/for the script, accessing RDH data, or becoming an API user, please contact info@redistrictingdatahub.org. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the four libraries needed to run the script. If you do not have these, you may need to install.\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "from getpass import getpass\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below is the baseurl used to retrieve the list of datasets on the website.\n",
    "baseurl = 'https://redistrictingdatahub.org/wp-json/download/list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function retrieves a list of all datasets on the RDH site. In order to run, you must be an API user and registered with the RDH site.\n",
    "Inputs: username (string), password (string)\n",
    "Optional Inputs: baseurl\"\"\"\n",
    "\n",
    "def get_list(username, password, states, baseurl=baseurl):\n",
    "    print('Retrieving list of datasets on RDH Website...')\n",
    "    if type(states)!=type([]):\n",
    "        states = [states]\n",
    "    dfs = []\n",
    "    for i in states:\n",
    "        params = {}\n",
    "        params['username'] = username\n",
    "        params['password'] = password\n",
    "        params['format'] = 'csv'\n",
    "        params['states'] = i\n",
    "        r = requests.get(baseurl, params=params)\n",
    "        data = r.content\n",
    "        try:\n",
    "            df = pd.read_csv(io.StringIO(data.decode('utf-8')))\n",
    "        except:\n",
    "            print('There was an error retrieving the list of datasets, please check that you have the correct password and username')\n",
    "            return \n",
    "        #display(df)\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_string(string_list, row):\n",
    "    if len(string_list)==0:\n",
    "        return True\n",
    "    for i in string_list:\n",
    "        if i not in row:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_states(state_list, row):\n",
    "    check_state = []\n",
    "    if state_list == ['']:\n",
    "        return True\n",
    "    else:\n",
    "        for i in state_list:\n",
    "            if i == row:\n",
    "                check_state.append(True)\n",
    "                return True\n",
    "            else:\n",
    "                check_state.append(False)\n",
    "        if any('True') in check_state:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_fullname(state):\n",
    "    state = state.lower()\n",
    "    keys = ['al','ak','az','ar','ca','co','ct','de','fl',\n",
    "              'ga','hi','id','il','in','ia','ks','ky','la','me',\n",
    "              'md','ma','mi','mn','ms','mo','mt','ne',\n",
    "              'nv','nh','nj','nm','ny','nc','nd','oh',\n",
    "              'ok','or','pa','ri','sc','sd','tn','tx',\n",
    "              'ut','vt','va','wa','wv','wi','wy']\n",
    "    values = ['Alabama','Alaska','Arizona','Arkansas','California','Colorado','Connecticut','Delaware','Florida',\n",
    "            'Georgia','Hawaii','Idaho','Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana','Maine',\n",
    "            'Maryland','Massachusetts','Michigan','Minnesota','Mississippi','Missouri','Montana','Nebraska',\n",
    "            'Nevada','New Hampshire','New Jersey','New Mexico','New York','North Carolina','North Dakota','Ohio',\n",
    "            'Oklahoma','Oregon','Pennsylvania','Rhode Island','South Carolina','South Dakota','Tennessee','Texas',\n",
    "            'Utah','Vermont','Virginia','Washington','West Virginia','Wisconsin','Wyoming']\n",
    "    values = [i.lower() for i in values]\n",
    "    dictionary = dict(zip(keys,values))\n",
    "    for k, v in dictionary.items():\n",
    "        if k == state:\n",
    "            return v\n",
    "        else:\n",
    "            continue\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_state_name(list_of_states):\n",
    "    new_list = []\n",
    "    for i in list_of_states:\n",
    "        state = assign_fullname(i)\n",
    "        new_list.append(state)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(run_no = 1):\n",
    "    if run_no == 1:\n",
    "        username = str(input('RDH Username or email: '))\n",
    "        password = str(getpass(prompt='RDH Password: '))\n",
    "    print('You can retrieve datasets by state by typing out the full state name or postal code abbreviation (e.g. \"Alabama\" or \"alabama\" or \"AL\" or \"al\").')\n",
    "    print('If you would like data for multiple states, please separate by comma (e.g. \"Wisconsin, mn\").')\n",
    "    print('Because of the limits of WordPress API, it can only retrieve a list of datasets for one state at a time (since many states have nearly 1,000 datasets), so if you are requesting data from multiple states this step may take several minutes, please be patient.')\n",
    "    state = str(input('\\nWhat state(s) do you want data for? Please separate by comma if multiple. '))\n",
    "    state = [i.strip() for i in state.split(',')]\n",
    "    state = [i.lower() for i in state]\n",
    "    state = run_state_name(state)\n",
    "    state = [i.lower() for i in state]\n",
    "\n",
    "    print('\\nYou can filter datasets in the state(s) you designated with the criteria listed below. All filter options are case insensitive.')\n",
    "    print('You may search by year as YYYY for all years from 2010 to 2021.')\n",
    "    print('You may search by dataset type with the following names: ACS5, CVAP, Projection, election results, voter file, incumbent, disag.')\n",
    "    print('You may search by geogrpahy with the following: precinct, block, block group, census tract, vtd, county, state, aiannh, zctas, senate districts, legislative districts, congressional districts, house of represenative districts (or other district names for the SLDL or SLDU for a given state -- \"districts\" will retrieve all district boundaries).')\n",
    "    print('***Please note that if you would like to retrieve the official redistricting dataset for your state, please use \"official\" (no quotations) in your query. Not all states will produce an offical dataset.')\n",
    "    print('You may search by file type as CSV or SHP.')\n",
    "    string = str(input('\\nAny other filtering parameters? Please separate by comma (e.g. \"election results, 2016, SHP\" etc). '))\n",
    "    string = [i.strip() for i in string.split(',')]\n",
    "    string = [i.lower() for i in string]\n",
    "    \n",
    "    if run_no ==1:\n",
    "        inputs = [username,password,state,string]\n",
    "    else:\n",
    "        inputs = [state,string]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''This function extracts the data that meets input specifications to the current working directory. In order to run, you must be an API user and registered with the RDH site.\n",
    "Inputs: username (string), password (string), state_name (string), add_string (list of strings)\n",
    "Output: N/A'''\n",
    "def get_data(run_no = 1,inputs=0,df = 0):\n",
    "    #get list of datasets\n",
    "    if (run_no == 1) or (run_no>1 and len(inputs)==1):\n",
    "        inputs = get_inputs()\n",
    "        username = inputs[0]\n",
    "        password = inputs[1]\n",
    "        state_name = inputs[2]\n",
    "        add_string = inputs[3]\n",
    "        df = get_list(username,password,state_name)\n",
    "    else:\n",
    "        username = inputs[0]\n",
    "        password = inputs[1]\n",
    "        inputs = get_inputs(run_no)\n",
    "        state_name = inputs[0]\n",
    "        add_string = inputs[1]\n",
    "        df = get_list(username,password,state_name)\n",
    "        inputs = [username,password,state_name,add_string]\n",
    "    #read in the list of data\n",
    "    for i in df.columns:\n",
    "        if 'Filter by state found 0 states or unknown states' in i:\n",
    "            print('*You did not specify the necessary states parameter.*')\n",
    "            inputs = [inputs[0],inputs[1],'fill','fill']#,df_save]\n",
    "            return inputs\n",
    "    if df.shape[0]<10:\n",
    "        print('\\nYou either have an incorrect username/password or you are not a designated API user. To try again, please re-run.')\n",
    "        print('If you continue to have problems or would like to become an API user, please email info@redistrictingdatahub.org')\n",
    "        inputs = [0]\n",
    "        return inputs\n",
    "    params = {\n",
    "    'username': username,\n",
    "    'password': password}\n",
    "    #subset the df by the additional string info\n",
    "    df['Title_Format'] = df.apply(lambda x: ' '.join([x['Title'],x['Format']]),axis=1)\n",
    "    df['Subset'] = df['Title_Format'].apply(lambda x: check_string(add_string,x.lower()))\n",
    "    df = df[df['Subset']==True].copy()\n",
    "    #take all of the urls in the subset df and split them to just get the baseurl of the dataset (no params)\n",
    "    urls = list(df['URL'])\n",
    "    new_urls = []\n",
    "    id_dict = {}\n",
    "    for i in urls:\n",
    "        new = i.split('?')[0]\n",
    "        dataset_id = i.split('&datasetid=')[1]\n",
    "        id_dict.update({new:dataset_id})\n",
    "        new_urls.append(new)\n",
    "    titles = list(df['Title_Format'])\n",
    "    if len(titles) == 0:\n",
    "        print('\\nThere are no datasets that currently meet your criteria. Please re-run with different criteria to extract data.')\n",
    "        inputs = [inputs[0],inputs[1],'fill','fill']#,df_save]\n",
    "        return inputs\n",
    "    else:\n",
    "        titles = ', '.join(titles)\n",
    "        print('\\nThe datasets to be extracted are: ', titles)\n",
    "    cont = str(input('\\nWould you like to extract these datasets to your current working directory? (Yes/No) '))\n",
    "    ftype = list(df['Format'])\n",
    "    data = dict(zip(new_urls,ftype))\n",
    "    cont = cont.capitalize()\n",
    "    \n",
    "    if cont == 'Yes':\n",
    "        counter = 1\n",
    "        #iterate over all of the new urls and retrieve the data\n",
    "        for i in new_urls:\n",
    "            print('Retrieving', str(counter), 'of',str(len(new_urls)),' files')\n",
    "            #get the data from the url and the params listed above\n",
    "            params.update({'datasetid':id_dict.get(i)})\n",
    "            response = requests.get(i,params)\n",
    "            #get the file name of the dataset\n",
    "            file_name = i.split('%2F')[-1]\n",
    "            file_name = file_name.split('/')[-1]\n",
    "            file_name_no_zip = file_name.split('.')[0]\n",
    "            zipdot = '.'+file_name.split('.')[1]\n",
    "            #because we have multiple datasets with the same name (for CSV and SHP), but we may want SHP or CSV, we need to make them unique filenames\n",
    "            for k,v in data.items():\n",
    "                if k == i:\n",
    "                    dtype = '_'+v.lower()\n",
    "                else:\n",
    "                    continue\n",
    "            #new filename\n",
    "            if dtype in file_name_no_zip:\n",
    "                dtype = ''\n",
    "            file_name = file_name_no_zip+dtype+zipdot\n",
    "            print('Retrieving ', file_name)\n",
    "            #write the data\n",
    "            file = open(file_name, \"wb\")\n",
    "            file.write(response.content)\n",
    "            file.close()\n",
    "            counter = counter+1\n",
    "        print('\\nDone extracting datasets to current working directory.')\n",
    "        print('Please re-run to extract additional data.')\n",
    "    else:\n",
    "        print('Data was not extracted. Please re-run if you would like to extract data.')\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_run(run_no, inputs):\n",
    "    run = str(input('\\nWould you like to run a new extraction? (Yes/No) '))\n",
    "    run = run.capitalize()\n",
    "    if run == 'Yes':\n",
    "        print('\\nStarting a new extraction..')\n",
    "        run_no = run_no+1\n",
    "        inputs = get_data(run_no,inputs)\n",
    "        re_run(run_no,inputs)\n",
    "    else:\n",
    "        print('\\nThanks for using the RDH API tool! If you want to run again, please re-run the run() function (you will be asked for username/password again).')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_versions():\n",
    "    pd_check = str((pd.__version__))=='1.3.1'\n",
    "    req_check = str(requests.__version__) == '2.25.1'\n",
    "    np_check = str(np.__version__)=='1.20.3'\n",
    "    if pd_check == False:\n",
    "        print('WARNING: You do not have the correct version of pandas to run this script. This script may still work, but you may need to install pandas version 1.3.1 for this script to work.')\n",
    "    if req_check == False:\n",
    "        print('WARNING: You do not have the correct version of requests to run this script. This script may still work, but you may need to install requests version 2.25.1 for this script to work.')\n",
    "    if np_check == False:\n",
    "        print('WARNING: You do not have the correct version of numpy to run this script. This script may still work, but you may need to install numpy version 1.20.3 for this script to work.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    check_versions()\n",
    "    run_no = 1\n",
    "    inputs = get_data()\n",
    "    re_run(run_no,inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
