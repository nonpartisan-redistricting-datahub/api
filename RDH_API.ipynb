{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script can be used to extract data from the RDH API. Designated API users can \"Run All\" and fill out the prompts as needed (e.g. username, password, states of interest, filtering paramters, etc.). You should not have to modify any of the code to retrieve data from the API, which will be extracted to the directory in which this script is housed on your system. If you have any questions or requests about/for the script, accessing RDH data, or becoming an API user, please contact info@redistrictingdatahub.org. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the four libraries needed to run the script. If you do not have these, you may need to install.\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "from getpass import getpass\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below is the baseurl used to retrieve the list of datasets on the website.\n",
    "baseurl = 'https://redistrictingdatahub.org/wp-json/download/list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function retrieves a list of all datasets on the RDH site. In order to run, you must be an API user and registered with the RDH site.\n",
    "Inputs: username (string), password (string)\n",
    "Optional Inputs: baseurl\"\"\"\n",
    "\n",
    "def get_list(username, password, baseurl=baseurl):\n",
    "    print('Retrieving list of datasets on RDH Website...')\n",
    "    params = {}\n",
    "    params['username'] = username\n",
    "    params['password'] = password\n",
    "    params['format'] = 'csv'\n",
    "    #check the header for the downloads\n",
    "    r = requests.get(baseurl, params=params)\n",
    "    data = r.content\n",
    "    df = pd.read_csv(io.StringIO(data.decode('utf-8')))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_string(string_list, row):\n",
    "    if len(string_list)==0:\n",
    "        return True\n",
    "    for i in string_list:\n",
    "        if i not in row:\n",
    "            #If the string from the list isn't in the row being searched, return False\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_states(state_list, row):\n",
    "    check_state = []\n",
    "    if state_list == ['']:\n",
    "        return True\n",
    "    else:\n",
    "        for i in state_list:\n",
    "            if i == row:\n",
    "                check_state.append(True)\n",
    "                return True\n",
    "            else:\n",
    "                check_state.append(False)\n",
    "        if any('True') in check_state:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_fullname(state):\n",
    "    state = state.lower()\n",
    "    keys = ['al','ak','az','ar','ca','co','ct','de','fl',\n",
    "              'ga','hi','id','il','in','ia','ks','ky','la','me',\n",
    "              'md','ma','mi','mn','ms','mo','mt','ne',\n",
    "              'nv','nh','nj','nm','ny','nc','nd','oh',\n",
    "              'ok','or','pa','ri','sc','sd','tn','tx',\n",
    "              'ut','vt','va','wa','wv','wi','wy']\n",
    "    values = ['Alabama','Alaska','Arizona','Arkansas','California','Colorado','Connecticut','Delaware','Florida',\n",
    "            'Georgia','Hawaii','Idaho','Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana','Maine',\n",
    "            'Maryland','Massachusetts','Michigan','Minnesota','Mississippi','Missouri','Montana','Nebraska',\n",
    "            'Nevada','New Hampshire','New Jersey','New Mexico','New York','North Carolina','North Dakota','Ohio',\n",
    "            'Oklahoma','Oregon','Pennsylvania','Rhode Island','South Carolina','South Dakota','Tennessee','Texas',\n",
    "            'Utah','Vermont','Virginia','Washington','West Virginia','Wisconsin','Wyoming']\n",
    "    values = [i.lower() for i in values]\n",
    "    dictionary = dict(zip(keys,values))\n",
    "    for k, v in dictionary.items():\n",
    "        if k == state:\n",
    "            return v\n",
    "        else:\n",
    "            continue\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_state_name(list_of_states):\n",
    "    new_list = []\n",
    "    for i in list_of_states:\n",
    "        state = assign_fullname(i)\n",
    "        new_list.append(state)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(run_no = 1):\n",
    "    if run_no == 1:\n",
    "        username = str(input('RDH Username: '))\n",
    "        password = str(getpass(prompt='RDH Password: '))\n",
    "    print('You can retrieve datasets by state by typing out the full state name or postal code abbreviation (e.g. \"Alabama\" or \"alabama\" or \"AL\" or \"al\").')\n",
    "    print('If you would like data for multiple states, please separate by comma (e.g. \"Wisconsin, mn\").')\n",
    "    print('If you would like data for all states, please leave blank.')\n",
    "    state = str(input('\\nWhat state(s) do you want data for? Please separate by comma if multiple. '))\n",
    "    state = [i.strip() for i in state.split(',')]\n",
    "    state = [i.lower() for i in state]\n",
    "    state = run_state_name(state)\n",
    "    state = [i.lower() for i in state]\n",
    "\n",
    "    print('\\nYou can filter datasets in the state(s) you designated with the criteria listed below. All filter options are case insensitive.')\n",
    "    print('You may search by year as YYYY for all years from 2010 to 2021.')\n",
    "    print('You may search by dataset type with the following names: ACS5, CVAP, Projection, election results, voter file, incumbent.')\n",
    "    print('You may search by geogrpahy with the following: precinct, block, block group, census tract, vtd, county, state, aiannh, zctas, senate districts, legislative districts, congressional districts, house of represenative districts (or other district names for the SLDL or SLDU for a given state -- \"districts\" will retrieve all district boundaries).')    \n",
    "    print('You may search by file type as CSV or SHP.')\n",
    "    string = str(input('\\nAny other filtering parameters? Please separate by comma (e.g. \"election results, 2016, SHP\" etc). '))\n",
    "    string = [i.strip() for i in string.split(',')]\n",
    "    string = [i.lower() for i in string]\n",
    "    \n",
    "    if run_no ==1:\n",
    "        inputs = [username,password,state,string]\n",
    "    else:\n",
    "        inputs = [state,string]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''This function extracts the data that meets input specifications to the current working directory. In order to run, you must be an API user and registered with the RDH site.\n",
    "Inputs: username (string), password (string), state_name (string), add_string (list of strings)\n",
    "Output: N/A'''\n",
    "def get_data(run_no = 1,inputs=0,df = 0):\n",
    "    #get list of datasets\n",
    "    if (run_no == 1) or (run_no>1 and len(inputs)==1):\n",
    "        inputs = get_inputs()\n",
    "        username = inputs[0]\n",
    "        password = inputs[1]\n",
    "        state_name = inputs[2]\n",
    "        add_string = inputs[3]\n",
    "        df = get_list(username,password)\n",
    "        df_save = df\n",
    "        inputs.append(df_save)\n",
    "    else:\n",
    "        username = inputs[0]\n",
    "        password = inputs[1]\n",
    "        df = inputs[4]###\n",
    "        df_save = df\n",
    "        inputs = get_inputs(run_no)\n",
    "        state_name = inputs[0]\n",
    "        add_string = inputs[1]\n",
    "        inputs = [username,password,state_name,add_string,df_save]\n",
    "    #read in the list of data\n",
    "    if df.shape[0]<10:\n",
    "        print('\\nYou either have an incorrect username/password or you are not a designated API user. To try again, please re-run.')\n",
    "        print('If you continue to have problems or would like to become an API user, please email info@redistrictingdatahub.org')\n",
    "        inputs = [0]\n",
    "        return inputs\n",
    "    params = (\n",
    "    ('username', username),\n",
    "    ('password', password),\n",
    "    )\n",
    "    \n",
    "    #Add state name to any VEST datasets that did not include that field\n",
    "    all_states = ['Alabama','Alaska','Arizona','Arkansas','California','Colorado','Connecticut','Delaware','Florida',\n",
    "            'Georgia','Hawaii','Idaho','Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana','Maine',\n",
    "            'Maryland','Massachusetts','Michigan','Minnesota','Mississippi','Missouri','Montana','Nebraska',\n",
    "            'Nevada','New Hampshire','New Jersey','New Mexico','New York','North Carolina','North Dakota','Ohio',\n",
    "            'Oklahoma','Oregon','Pennsylvania','Rhode Island','South Carolina','South Dakota','Tennessee','Texas',\n",
    "            'Utah','Vermont','Virginia','Washington','West Virginia','Wisconsin','Wyoming']\n",
    "    null = df[~df['State'].isin(all_states)].copy()\n",
    "    null_titles = list(null['Title'])\n",
    "    df = df[~df['Title'].isin(null_titles)].copy()\n",
    "    null = null[null['Title']!='test'].copy()\n",
    "    null['State'] = null['Title'].apply(lambda x: x.split(' ')[2])\n",
    "    df = pd.concat([null,df])\n",
    "    \n",
    "    #subset the df by state name\n",
    "    df['Subset'] = df['State'].apply(lambda x:check_states(state_name, x.lower()))\n",
    "    df = df[df['Subset']==True].copy()\n",
    "    #subset the df by the additional string info\n",
    "    df['Title_Format'] = df.apply(lambda x: ' '.join([x['Title'],x['Format']]),axis=1)\n",
    "    df['Subset'] = df['Title_Format'].apply(lambda x: check_string(add_string,x.lower()))\n",
    "    df = df[df['Subset']==True].copy()\n",
    "    #take all of the urls in the subset df and split them to just get the baseurl of the dataset (no params)\n",
    "    urls = list(df['URL'])\n",
    "    new_urls = []\n",
    "    for i in urls:\n",
    "        new = i.split('?')[0]\n",
    "        new_urls.append(new)\n",
    "    titles = list(df['Title_Format'])\n",
    "    if len(titles) == 0:\n",
    "        print('\\nThere are no datasets that currently meet your criteria. Please re-run with different criteria to extract data.')\n",
    "        inputs = [inputs[0],inputs[1],'fill','fill',df_save]\n",
    "        return inputs\n",
    "    else:\n",
    "        titles = ', '.join(titles)\n",
    "        print('\\nThe datasets to be extracted are: ', titles)\n",
    "    cont = str(input('\\nWould you like to extract these datasets to your current working directory? (Yes/No) '))\n",
    "    ftype = list(df['Format'])\n",
    "    data = dict(zip(new_urls,ftype))\n",
    "    cont = cont.capitalize()\n",
    "    if cont == 'Yes':\n",
    "        counter = 1\n",
    "        #iterate over all of the new urls and retrieve the data\n",
    "        for i in new_urls:\n",
    "            print('Retrieving', str(counter), 'of',str(len(new_urls)),'files')\n",
    "            #get the data from the url and the params listed above\n",
    "            response = requests.get(i,params)\n",
    "            #get the file name of the dataset\n",
    "            file_name = i.split('%2F')[-1]\n",
    "            file_name = file_name.split('/')[-1]\n",
    "            file_name_no_zip = file_name.split('.')[0]\n",
    "            zipdot = '.'+file_name.split('.')[1]\n",
    "            #because we have multiple datasets with the same name (for CSV and SHP), but we may want SHP or CSV, we need to make them unique filenames\n",
    "            for k,v in data.items():\n",
    "                if k == i:\n",
    "                    dtype = '_'+v.lower()\n",
    "                else:\n",
    "                    continue\n",
    "            #new filename\n",
    "            if dtype in file_name_no_zip:\n",
    "                dtype = ''\n",
    "            file_name = file_name_no_zip+dtype+zipdot\n",
    "            print('Retrieving ', file_name)\n",
    "            #write the data\n",
    "            file = open(file_name, \"wb\")\n",
    "            file.write(response.content)\n",
    "            file.close()\n",
    "            counter = counter+1\n",
    "        print('\\nDone extracting datasets to current working directory.')\n",
    "        print('Please re-run to extract additional data.')\n",
    "    else:\n",
    "        print('Data was not extracted. Please re-run if you would like to extract data.')\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_run(run_no, inputs):\n",
    "    run = str(input('\\nWould you like to run a new extraction? (Yes/No) '))\n",
    "    run = run.capitalize()\n",
    "    if run == 'Yes':\n",
    "        print('\\nStarting a new extraction..')\n",
    "        run_no = run_no+1\n",
    "        inputs = get_data(run_no,inputs)\n",
    "        re_run(run_no,inputs)\n",
    "    else:\n",
    "        print('\\nThanks for using the RDH API tool! If you want to run again, please re-run the run() function (you will be asked for username/password again).')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    run_no = 1\n",
    "    inputs = get_data()\n",
    "    re_run(run_no,inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
